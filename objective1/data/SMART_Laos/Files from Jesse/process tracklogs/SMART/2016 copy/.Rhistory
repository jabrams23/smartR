'gWidgets2RGtk2' = gfile(type = 'selectdir', text = title),
readline('Please enter directory path: ')
)
}
# choose parent data directory whose subordinate directories contain the images
# test if parent data directory was already provided when vegimages was called
if (is.null(query.path) == T){
message("\nPlease choose path to superordinate data folder\n")
query.path = choose_directory()
}
choose_directory()
install.packages("FedData")
library(FedData)
choose_directory()
?pkgTest
install.packages("pkgload")
library(pkgload)
?pkgTest
?pkgtest
install.packages("AutoGLM")
libraru(rstudioapi)
library(rstudioapi)
?pkgtest
# define parent directory containing the pictures
# The following function tries out a sequence of potential methods for selecting a directory to find one that works
# Its fallback default method if nothing else works is to get user input from the console
select_directory_method = function(){
if (!exists('.dir.method'))
{
if (exists('utils::choose.dir'))
{
.dir.method = 'choose.dir'
} else
if (rstudioapi::isAvailable() & rstudioapi::getVersion() > '1.1.287')
{
.dir.method = 'RStudioAPI'
library('rstudioapi')
} else
if (ensure_library('tcltk') & class(try({tt = tktoplevel(); tkdestroy(tt)}, silent = T)) != "try-error")
{
.dir.method = 'tcltk'
} else
if (library('gWidgets2') & library('RGtk2'))
{
.dir.method = 'gWidgets2RGtk2'
} else
if (library('rJava') & library('rChoiceDialogs'))
{
.dir.method = 'rChoiceDialogs'
} else
{
.dir.method = 'console'
}
assign('.dir.method', .dir.method, envir = .GlobalEnv) # remember the chosen method for later
}
return(.dir.method)
}
# function to chose directory
choose_directory = function(method = select_directory_method(), title = 'choose directory'){
switch (method,
'choose.dir' = choose.dir(caption = title),
'RStudioAPI' = selectDirectory(caption = title, path = "/"),
'tcltk' = tk_choose.dir(caption = title),
'rChoiceDialogs' = rchoose.dir(caption = title),
'gWidgets2RGtk2' = gfile(type = 'selectdir', text = title),
readline('Please enter directory path: ')
)
}
# choose parent data directory whose subordinate directories contain the images
# test if parent data directory was already provided when vegimages was called
if (is.null(query.path) == T){
message("\nPlease choose path to superordinate data folder\n")
query.path = choose_directory()
}
choose_directory()
pkgtest(ggplot2)
pkgtest(tcltk)
install.packages("revtools")
library(revtools)
install.packages("litsearchr")
install.packages("‘statcheck’")
install.packages("statcheck")
install.packages("metafor")
install.packages("metagear")
install.packages("metagear")
install.packages("Adjutant")
install.packages("RISmed")
install.packages("revtools")
install.packages("revtools")
##OPEN USER-DEFINED FUNCTIONS AND RAW TRACKLOG POINT DATA
library(rgeos);
library (rgdal)
villages <- readOGR("Desktop","All_Villages_VN_LAOS_around_NNT")
library(raster)
?raster
heatmap <- raster("village_density_10000_layer units.tif")
heatmap <- raster("~/Desktop/village_density_10000_layer units.tif")
plot(heatmap)
plot(villages,add=TRUE)
heatmap2 <- flip(heatmap)
heatmap2 <- flip(heatmap,direction='y')
plot(heatmap2)
plot(villages,add=TRUE)
villages2 <- flip(villages,direction='y')
villages2 <- rasterize(villages)
##OPEN USER-DEFINED FUNCTIONS AND RAW TRACKLOG POINT DATA
library(rgeos)
library(rgdal)
library(raster)
villages <- readOGR("Desktop","All_Villages_VN_LAOS_around_NNT")
heatmap <- raster("~/Desktop/village_density_10000_layer units.tif")
heatmap2 <- flip(heatmap,direction='y')
plot(heatmap2)
plot(villages,add=TRUE)
mypath <- "~/Dropbox (ScreenForBio)/WWF Vietnam SMART data/Vietnam/Tracklog 2011 - 2019/SMART/2014/effort"
filenames <- list.files(path = mypath, full.names = TRUE)
myfiles <- lapply(filenames, read.csv)
mydata3 <- Reduce(function(dtf1, dtf2) merge(dtf1, dtf2,
by = intersect(colnames(dtf1),colnames(dtf2)),
all.x = TRUE),myfiles)
mydata3 <- mydata3[,colSums(is.na(mydata3))<nrow(mydata3)]
mydata2$X <- NULL
mydata3 <- Reduce(function(dtf1, dtf2) merge(dtf1, dtf2,
by = intersect(colnames(dtf1),colnames(dtf2)),
all.x = TRUE),myfiles)
mydata3$X <- NULL
mydata3$NA. <- NULL
cols.nam <- colnames(mydata3)
cols.nam <- str_sub(cols.nam, 2, 11)
library("stringr")
cols.nam <- str_sub(cols.nam, 2, 11)
length(unique(cols.nam))
mydata3 <- mydata3
colnames(mydata3) <- cols.nam
mydata3 <- mydata3[ , order(names(mydata3))]
?merge
myfiles <- lapply(filenames, read.csv)
mydata3 <- Reduce(function(dtf1, dtf2) merge(dtf1, dtf2,
by = intersect(names(dtf1),names(dtf2)),
all.x = TRUE,sort=TRUE),myfiles)
mydata3$X <- NULL
mydata3$NA. <- NULL
cols.nam <- colnames(mydata3)
cols.nam <- str_sub(cols.nam, 2, 11)
length(unique(cols.nam))
colnames(mydata3) <- cols.nam
mydata3 <- mydata3[ , order(names(mydata3))]
mydata4 <- mydata3[,colSums(is.na(mydata3))<nrow(mydata3)]
myfiles <- rapply(myfiles,function(x) ifelse(x==0,NA,x), how = "replace")
?natural_join
install.packages("rqdatatable")
?full_join
library(rqdatatable)
?natural_join
mydata4 <- Reduce(function(dtf1, dtf2) natural_join(dtf1, dtf2,
by = intersect(names(dtf1),names(dtf2)),
jointype = "FULL"),myfiles)
library(dplyr)
?full_join
mydata4 <- Reduce(function(dtf1, dtf2) full_join(dtf1, dtf2,
by = intersect(names(dtf1),names(dtf2))),myfiles)
?dplyr::coalesce
View(mydata3)
mydata4 <- mydata3[,colSums(is.na(mydata4))<nrow(mydata4)]
mydata4 <- mydata4[,colSums(is.na(mydata4))<nrow(mydata4)]
mydata4[,1]
length(unique(mydata4[,1])
)
View(mydata4)
mydata4 <- Reduce(function(dtf1, dtf2) coalesce(dtf1, dtf2),myfiles)
mydata45 <- mydata4 %>%
left_join(df2, by = "X") %>%
mutate(var2 = coalesce(var2.x, var2.y)) %>%
select(-var2.x, -var2.y)
mydata45 <- mydata4 %>%
left_join(mydata4, by = "X") %>%
mutate(var2 = coalesce(var2.x, var2.y)) %>%
select(-var2.x, -var2.y)
?Reduce
mydata4 <- Reduce(function(dtf1, dtf2) full_join(dtf1, dtf2,
by = intersect(names(dtf1),names(dtf2))),myfiles)
mypath <- "~/Dropbox (ScreenForBio)/WWF Vietnam SMART data/Vietnam/Tracklog 2011 - 2019/SMART/2014/effort"
filenames <- list.files(path = mypath, full.names = TRUE)
myfiles <- lapply(filenames, read.csv)
mydata4 <- Reduce(function(dtf1, dtf2) full_join(dtf1, dtf2,
by = intersect(names(dtf1),names(dtf2))),myfiles)
mypath <- "~/Dropbox (ScreenForBio)/WWF Vietnam SMART data/Vietnam/Tracklog 2011 - 2019/SMART/2014/effort"
filenames <- list.files(path = mypath, full.names = TRUE)
myfiles <- lapply(filenames, read.csv)
#myfiles <- rapply(myfiles,function(x) ifelse(x==0,NA,x), how = "replace")
myfiles <- rapply(myfiles,function(x) ifelse(is.na(x),0,x), how = "replace")
library(rqdatatable)
library(dplyr)
library(tidyverse)
mydata4 <- Reduce(function(dtf1, dtf2) full_join(dtf1, dtf2,
by = intersect(names(dtf1),names(dtf2))),myfiles)
rownames(mydata4) <- mydata4$X
rownames(mydata4)
mydata5 <- aggregate(. ~ X, FUN = sum, mydata4)
View(mydata5)
lenght(unique(mydata4$X))
length(unique(mydata4$X))
is.na(mydata4)
max(mydata4)
mydata4[is.na(mydata4)] <- 0
max(mydata4)
mydata5 <- aggregate(. ~ X, FUN = sum, mydata4)
rownames(mydata5) <- mydata5$X
mydata5$X <- NULL
mydata5 <- mydata5[ , order(names(mydata5))]
unique(mydata5$X2014.10.29)
cols.nam <- colnames(mydata5)
cols.nam <- str_sub(cols.nam, 2, 11)
length(unique(cols.nam))
colnames(mydata5) <- cols.nam
mydata5 <- aggregate(. ~ X, FUN = sum, mydata4)
rownames(mydata5) <- mydata5$X
mydata5$X <- NULL
mydata5 <- mydata5[ , order(names(mydata5))]
mydata5$NA. <- NULL
mydata5 <- mydata5[ , order(names(mydata5))]
library("stringr")
cols.nam <- colnames(mydata5)
cols.nam <- str_sub(cols.nam, 2, 11)
length(unique(cols.nam))
colnames(mydata5) <- cols.nam
write.csv(mydata5,"effort_2014.csv")
library(sf)
library(raster)
library(SDraw)
library(mapview)
library(sp)
library(rgeos)
library(rgdal)
library(foreach)
Sys.setenv(TZ='Asia/Ho_Chi_Minh')
Sys.timezone() ## Check. should now say 'Asia/Ho_Chi_Minh'
time.zone = "Asia/Ho_Chi_Minh" ##in case this is ever in question!
# read in paths
setwd("~/Dropbox (ScreenForBio)/WWF Vietnam SMART data/Vietnam/Tracklog 2011 - 2019/SMART")
source("~/Dropbox (ScreenForBio)/WWF Vietnam SMART data/Modified_SMART_data_processing/functions/Initial_tracklog_processing.R")
#Identify folder where tracklogs are stored.
wd.gps <- "~/Dropbox (ScreenForBio)/WWF Vietnam SMART data/Vietnam/Tracklog 2011 - 2019/SMART/2015"
###########################################
# extract  spatial point data frames, one for each file, and store as a list
AllTracks <- ReadgpxTracks (wd.in = wd.gps, include.subdirs = TRUE)
##LIST AND REMOVE FROM AllTracks FILES WHICH COULDN'T BE READ.
unreadable <- names(which(sapply(AllTracks,is.null)))
AllTracks <- AllTracks[which(!names(AllTracks) %in% unreadable)]
empty <- names(which(sapply(AllTracks,function(x){nrow(x@data)==0})))
# there are no empty ones (which aren't unreadable) so next line does nothing
AllTracks <- AllTracks[which(!names(AllTracks) %in% empty)]
grid <- readOGR("~/Dropbox (ScreenForBio)/Wilkinson_RESHARE/empty_grids","grid_500_m_saola_PAs")
setwd("~/Dropbox (ScreenForBio)/WWF Vietnam SMART data/Vietnam/Tracklog 2011 - 2019/SMART/2015/effort")
library(doParallel)
registerDoParallel(cores=4)
k>-1
k<-1
track_name <- names(AllTracks[k])
track_name <- substr(track_name,1,nchar(track_name)-4)
#track_name <- sub("\\..*", "", track_name)
track_name <- gsub("/", "_", track_name)
track_name <- gsub(".", "_", track_name)
track_name <- names(AllTracks[k])
track_name <- substr(track_name,1,nchar(track_name)-4)
#track_name <- sub("\\..*", "", track_name)
track_name <- gsub("/", "_", track_name)
track_name <- gsub("\\.", "_", track_name)
track_name <- gsub(" ", "_", track_name)
library(doParallel)
registerDoParallel(cores=4)
#for (k in (length(AllTracks)/2):(length(AllTracks))) {
foreach(k=1:length(AllTracks)) %dopar% {
library(sf)
library(raster)
library(SDraw)
library(mapview)
library(sp)
library(rgeos)
library(rgdal)
library(foreach)
track_name <- names(AllTracks[k])
track_name <- substr(track_name,1,nchar(track_name)-4)
#track_name <- sub("\\..*", "", track_name)
track_name <- gsub("/", "_", track_name)
track_name <- gsub("\\.", "_", track_name)
track_name <- gsub(" ", "_", track_name)
track_point <- AllTracks[[k]]
track_point <- spTransform(track_point, CRS("+proj=utm +zone=48 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0"))
track_points <- crop(track_point,grid)
track_points$date <- track_points$time
track_points$date <- format(as.POSIXct(track_points$date,format='%Y/%m/%d %H:%M:%S'),format='%Y/%m/%d')
track_points$date <- as.character(track_points$date)
un.date <- unique(track_points$date)
effort <- grid
effort@data$length <- 0
effort@data$percent_covered <- 0
cell_size <- 500*500
effort_table <- array(NA,c(length(grid@polygons),length(un.date)))
for (i in 1:length(un.date)) {
#subset to one day
tmp <- subset(track_points, (date == un.date[i]))
#order points by time
tmp2 <- tmp[order(tmp$time),]
#turn points into line
#test2 <- points_to_line(tmp2)
#points_to_line is not working...not sure why
un.coords <- unique(tmp2@coords)
if (dim(un.coords)[1] >1) {
track_lines <- coords2Lines(tmp2@coords, ID=un.date[i])
proj4string(track_lines) <- "+proj=utm +zone=48 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0"
b_track_lines <- gBuffer(track_lines, width=20)
#assign projection
#proj4string(track_lines) <- "+proj=utm +zone=48 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0"
gI <- gIntersection(grid,b_track_lines, byid=c(TRUE, TRUE))
for (j in 1:length(grid@polygons)) {
print(j)
#take first grid cell
tmp4 <- grid[j,]
#make new extent for lines for the day in question
ext.tmp <- extent(min(tmp@coords[,1]),
max(tmp@coords[,1]),
min(tmp@coords[,2]),
max(tmp@coords[,2]))
#check if there was any activity in the current grid cell
#inter <- intersect(ext.tmp, extent(tmp4))
inter <- gIntersects(tmp4,gI, byid=TRUE)
#if there was effort figure out the distance covered
if (any(inter==TRUE)) {
print(j)
print("TRUE!")
#crop the line to the cell of interest
cell_poly <- crop(gI, extent(tmp4))
#calculate the length of the line or "distance covered"
tmp_distance <- area(cell_poly) #lineLength(cell_poly) # THIS WORKS FINE IF I CAN GET THE SHAPEFILE CROPPED PROPERLY
#assign this to the effort shapefile
effort@data$length[j] <- tmp_distance
effort@data$percent_covered <- tmp_distance/cell_size
#if not set effort to 0
} else {
effort@data$length[j] <- 0
effort@data$percent_covered <- 0
}
effort_table[j,i] <- effort@data$length[j]
}
}
}
effort_table <- as.data.frame(effort_table)
colnames(effort_table) <- un.date
rownames(effort_table) <- seq(1,length(grid@polygons))
write.csv(effort_table,paste("effort_table_polygons_",track_name,".csv",sep=""))
}
library(plyr)
library(readr)
library(tidyverse)
library(rqdatatable)
library(dplyr)
library(stringr)
setwd("~/Dropbox (ScreenForBio)/WWF Vietnam SMART data/Vietnam/Tracklog 2011 - 2019/SMART/2015")
mypath <- "~/Dropbox (ScreenForBio)/WWF Vietnam SMART data/Vietnam/Tracklog 2011 - 2019/SMART/2015/effort"
filenames <- list.files(path = mypath, full.names = TRUE)
myfiles <- lapply(filenames, read.csv)
myfiles <- rapply(myfiles,function(x) ifelse(is.na(x),0,x), how = "replace")
mydata4 <- Reduce(function(dtf1, dtf2) full_join(dtf1, dtf2,
by = intersect(names(dtf1),names(dtf2))),myfiles)
mydata4[is.na(mydata4)] <- 0
mydata5 <- aggregate(. ~ X, FUN = sum, mydata4)
rownames(mydata5) <- mydata5$X
mydata5$X <- NULL
mydata5$NA. <- NULL
mydata5 <- mydata5[ , order(names(mydata5))]
cols.nam <- colnames(mydata5)
cols.nam <- str_sub(cols.nam, 2, 11)
length(unique(cols.nam))
colnames(mydata5) <- cols.nam
cols.nam
View(mydata5)
write.csv(mydata5,"effort_2015.csv")
library(sf)
library(raster)
library(SDraw)
library(mapview)
library(sp)
library(rgeos)
library(rgdal)
library(foreach)
Sys.setenv(TZ='Asia/Ho_Chi_Minh')
Sys.timezone() ## Check. should now say 'Asia/Ho_Chi_Minh'
time.zone = "Asia/Ho_Chi_Minh" ##in case this is ever in question!
# read in paths
setwd("~/Dropbox (ScreenForBio)/WWF Vietnam SMART data/Vietnam/Tracklog 2011 - 2019/SMART")
source("~/Dropbox (ScreenForBio)/WWF Vietnam SMART data/Modified_SMART_data_processing/functions/Initial_tracklog_processing.R")
#Identify folder where tracklogs are stored.
wd.gps <- "~/Dropbox (ScreenForBio)/WWF Vietnam SMART data/Vietnam/Tracklog 2011 - 2019/SMART/2016"
###########################################
# extract  spatial point data frames, one for each file, and store as a list
AllTracks <- ReadgpxTracks (wd.in = wd.gps, include.subdirs = TRUE)
##LIST AND REMOVE FROM AllTracks FILES WHICH COULDN'T BE READ.
unreadable <- names(which(sapply(AllTracks,is.null)))
AllTracks <- AllTracks[which(!names(AllTracks) %in% unreadable)]
empty <- names(which(sapply(AllTracks,function(x){nrow(x@data)==0})))
# there are no empty ones (which aren't unreadable) so next line does nothing
AllTracks <- AllTracks[which(!names(AllTracks) %in% empty)]
grid <- readOGR("~/Dropbox (ScreenForBio)/Wilkinson_RESHARE/empty_grids","grid_500_m_saola_PAs")
setwd("~/Dropbox (ScreenForBio)/WWF Vietnam SMART data/Vietnam/Tracklog 2011 - 2019/SMART/2016/effort")
library(doParallel)
registerDoParallel(cores=4)
#for (k in (length(AllTracks)/2):(length(AllTracks))) {
foreach(k=1:length(AllTracks)) %dopar% {
library(sf)
library(raster)
library(SDraw)
library(mapview)
library(sp)
library(rgeos)
library(rgdal)
library(foreach)
track_name <- names(AllTracks[k])
track_name <- substr(track_name,1,nchar(track_name)-4)
#track_name <- sub("\\..*", "", track_name)
track_name <- gsub("/", "_", track_name)
track_name <- gsub("\\.", "_", track_name)
track_name <- gsub(" ", "_", track_name)
track_point <- AllTracks[[k]]
track_point <- spTransform(track_point, CRS("+proj=utm +zone=48 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0"))
track_points <- crop(track_point,grid)
track_points$date <- track_points$time
track_points$date <- format(as.POSIXct(track_points$date,format='%Y/%m/%d %H:%M:%S'),format='%Y/%m/%d')
track_points$date <- as.character(track_points$date)
un.date <- unique(track_points$date)
effort <- grid
effort@data$length <- 0
effort@data$percent_covered <- 0
cell_size <- 500*500
effort_table <- array(NA,c(length(grid@polygons),length(un.date)))
for (i in 1:length(un.date)) {
#subset to one day
tmp <- subset(track_points, (date == un.date[i]))
#order points by time
tmp2 <- tmp[order(tmp$time),]
#turn points into line
#test2 <- points_to_line(tmp2)
#points_to_line is not working...not sure why
un.coords <- unique(tmp2@coords)
if (dim(un.coords)[1] >1) {
track_lines <- coords2Lines(tmp2@coords, ID=un.date[i])
proj4string(track_lines) <- "+proj=utm +zone=48 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0"
b_track_lines <- gBuffer(track_lines, width=20)
#assign projection
#proj4string(track_lines) <- "+proj=utm +zone=48 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0"
gI <- gIntersection(grid,b_track_lines, byid=c(TRUE, TRUE))
for (j in 1:length(grid@polygons)) {
print(j)
#take first grid cell
tmp4 <- grid[j,]
#make new extent for lines for the day in question
ext.tmp <- extent(min(tmp@coords[,1]),
max(tmp@coords[,1]),
min(tmp@coords[,2]),
max(tmp@coords[,2]))
#check if there was any activity in the current grid cell
#inter <- intersect(ext.tmp, extent(tmp4))
inter <- gIntersects(tmp4,gI, byid=TRUE)
#if there was effort figure out the distance covered
if (any(inter==TRUE)) {
print(j)
print("TRUE!")
#crop the line to the cell of interest
cell_poly <- crop(gI, extent(tmp4))
#calculate the length of the line or "distance covered"
tmp_distance <- area(cell_poly) #lineLength(cell_poly) # THIS WORKS FINE IF I CAN GET THE SHAPEFILE CROPPED PROPERLY
#assign this to the effort shapefile
effort@data$length[j] <- tmp_distance
effort@data$percent_covered <- tmp_distance/cell_size
#if not set effort to 0
} else {
effort@data$length[j] <- 0
effort@data$percent_covered <- 0
}
effort_table[j,i] <- effort@data$length[j]
}
}
}
effort_table <- as.data.frame(effort_table)
colnames(effort_table) <- un.date
rownames(effort_table) <- seq(1,length(grid@polygons))
write.csv(effort_table,paste("effort_table_polygons_",track_name,".csv",sep=""))
}
library(plyr)
library(readr)
library(tidyverse)
library(rqdatatable)
library(dplyr)
library(stringr)
setwd("~/Dropbox (ScreenForBio)/WWF Vietnam SMART data/Vietnam/Tracklog 2011 - 2019/SMART/2016")
mypath <- "~/Dropbox (ScreenForBio)/WWF Vietnam SMART data/Vietnam/Tracklog 2011 - 2019/SMART/2016/effort"
filenames <- list.files(path = mypath, full.names = TRUE)
myfiles <- lapply(filenames, read.csv)
myfiles <- rapply(myfiles,function(x) ifelse(is.na(x),0,x), how = "replace")
mydata4 <- Reduce(function(dtf1, dtf2) full_join(dtf1, dtf2,
by = intersect(names(dtf1),names(dtf2))),myfiles)
mydata4[is.na(mydata4)] <- 0
mydata5 <- aggregate(. ~ X, FUN = sum, mydata4)
rownames(mydata5) <- mydata5$X
mydata5$X <- NULL
mydata5$NA. <- NULL
mydata5 <- mydata5[ , order(names(mydata5))]
cols.nam <- colnames(mydata5)
cols.nam <- str_sub(cols.nam, 2, 11)
length(unique(cols.nam))
colnames(mydata5) <- cols.nam
write.csv(mydata5,"effort_2016.csv")
