#rew[i]<-tmp[[2]]
#route[[i]]<-as.vector(tmp[[1]])
}
for (k in 1:numb) {
rew[k]<-as.vector(tmp_test[[k]][2])
route[k]<-as.vector(tmp_test[[k]][1])
}
ten_percent <- 0.1 * numb
rew <- unlist(rew)
tmp2 <- sort(rew, decreasing = TRUE)
tmp_10 <- tmp2[ten_percent]
selected_routes <- route[which(rew>=tmp_10)]
return(selected_routes)
}
update_transition <- function(cost_matrix,tran_mat,select){
tmp1 <- unlist(select)
tmp3 <- as.data.frame(table(tmp1))
tran_mat@data@values[!is.na(tran_mat@data@values)] <- 0
tran_mat@data@values[tmp3$tmp1] <- as.vector(tmp3$Freq)/numb
tran_mat@data@values <- ifelse(tran_mat@data@values>1, 1, tran_mat@data@values)
return(tran_mat)
}
range01 <- function(x){(x-min(x))/(max(x)-min(x))}
########## TESTING
road_map <- raster(ncol=10, nrow=10)
values(road_map) <- 1:ncell(road_map)
reward_layer <- road_map
values(reward_layer) <- sample(seq(0,100),100,replace=TRUE)
cost_layer <- road_map
values(cost_layer) <- sample(seq(0,10),100,replace=TRUE)
values(cost_layer) <- range01(values(cost_layer))
transition_mat <- cost_layer
values(transition_mat) <- 0.0
numb<-10
reps<-100
for (i in 1:reps) {
transition_mat <- (0.5*(1-cost_layer))+(0.5*transition_mat)
test <- ce(numb,transition_mat,cost_layer,reward_layer,100)
transition_mat <- update_transition(cost_layer,transition_mat,test)
plot(transition_mat)
}
# Courtesy of Dr. Fiona Spooner, University of Exeter
# Hacked to bits by Kevin Donkers...
library(sf)
# library(vroom)
library(ggplot2)
library(dplyr)
library(here)
library(readr)
library(colorspace)
# Load data
bristl <- read.csv(here("URBN-CLIMR/data/population_data/lad_tus_hse_23.txt"))
msoa <- st_read(here("URBN-CLIMR/data/msoa_shapefiles/bristol_msoas.shp"))
rivers <- st_read(here("URBN-CLIMR/data/os_open_rivers/data/WatercourseLink.shp"))
green <- st_read(here("URBN-CLIMR/data/os_open_green_space/data/GB_AccessPoint.shp"))
bristl <- read.csv("~/OneDrive - University of Exeter/URBN_CLIMR/data/population_data/lad_tus_hse_23.txt")
msoa <- st_read("~/OneDrive - University of Exeter/URBN_CLIMR/data/msoa_shapefiles/bristol_msoas.shp")
rivers <- st_read("~/OneDrive - University of Exeter/URBN_CLIMR/data/os_open_rivers/data/WatercourseLink.shp")
green <- st_read("~/OneDrive - University of Exeter/URBN_CLIMR/data/os_open_green_space/data/GB_AccessPoint.shp")
# Demographic data wrangle
bris_sum <- bristl %>%
group_by(area) %>%
summarise(mean_wage = mean(medianhourlypay, na.rm = TRUE), mean_age = mean(age))
bris_geo <- msoa %>%
filter(msoa11cd %in% bris_sum$area) %>%
left_join(., bris_sum, by =c("msoa11cd" = "area", "mean_wage", "mean_age"))
# "Normalised" mean age
bris_geo$mean_age_n = (bris_geo$mean_age - 20)/max(bris_geo$mean_age - 20)
# Rivers and greenspace data wrangle
rivers_bris <- rivers %>%
st_crop(st_bbox(bris_geo))
green_bris <- green %>%
st_crop(st_bbox(bris_geo))
bris_geo$green_count <- lengths(st_intersects(bris_geo, green_bris))
# Normalised greenspace
bris_geo$green_count_n <- bris_geo$green_count/max(bris_geo$green_count)
# Plots:
# Rivers
ggplot(rivers_bris)+
geom_sf()
# Mean wage
ggplot() +
geom_sf(data = bris_geo,aes(fill = mean_wage, color = mean_wage))+
scale_color_continuous_sequential(palette = "Greens", rev=FALSE,
name="Average Wage (£/hr)")+
scale_fill_continuous_sequential(palette = "Greens", rev=FALSE,
name="Average Wage (£/hr)")+
# geom_sf(data = rivers_bris, colour = "blue")+
theme_dark()
# Mean age
bris_geo %>%
ggplot(data = .) +
geom_sf(aes(fill = mean_age_n, colour = mean_age_n))+
scale_color_continuous_sequential(palette = "Blues", rev=TRUE,
name="Average age (years)")+
scale_fill_continuous_sequential(palette = "Blues", rev=TRUE,
name="Average age (years)")+
theme_dark()
ggplot() +
geom_sf(data = bris_geo, aes(fill = green_count_n, color=green_count_n)) +
scale_color_continuous_sequential(palette = "Greens", rev=FALSE, name="Number of green spaces")+
scale_fill_continuous_sequential(palette = "Greens", rev=FALSE, name="Number of green spaces") +
theme_dark() +
theme(legend.position="none")
# geom_sf(data = green_bris, aes(color = accessType))
library(raster)
library(ncdf4)
tmax <- nc_open("~/OneDrive - University of Exeter/URBN_CLIMR/data/UKCP/tasmax_rcp85_land-cpm_uk_2.2km_01_day_19801201-19811130.nc")
lon <- ncvar_get(tmax,"longitude")
nlon <- dim(lon)
lat <- ncvar_get(tmax,"latitude")
nlat <- dim(lat)
t_max <- ncvar_get(tmax,"tasmax")
time <- ncvar_get(tmax,"yyyymmdd")
tmp <- t_max[,,1]
library(reshape2)
tmp1 <- melt(lon)
tmp2 <- melt(lat)
tmp3 <- melt(tmp)
df <- data.frame(lat=tmp2$value,
lon=tmp1$value,
temp=tmp3$value)
projcrs <- projection(bris_geo)
temp_df <- st_as_sf(x = df,
coords = c("lon", "lat"),
crs = projcrs)
temp <- crop(temp_df,bris_geo)
temp <- st_crop(temp_df,bris_geo)
type(temp_df)
class9Temp_df
class(temp_df)
class(bris_geo)
class(green)
temp_bris <- temp_df %>%
st_crop(st_bbox(bris_geo))
projection(temp_df)
projection(bris_geo)
temp_bris <- temp_df %>%
st_crop(st_bbox(bris_geo))
st_crs(bris_geo)
st_crs(temp_bris)
st_crs(temp_df)
projcrs <- st_crs(bris_geo)
temp_df <- st_as_sf(x = df,
coords = c("lon", "lat"),
crs = projcrs)
temp_bris <- temp_df %>%
st_crop(st_bbox(bris_geo))
ggplot() +
geom_sf(data = temp_df)
ggplot() +
geom_sf(data = temp_bris)
st_bbox(temp_df)
st_bbox(bris_geo)
st_bbox(green)
temp_df <- st_as_sf(x = df,
coords = c("lon", "lat"),
crs = "+proj=longlat +datum=WGS84 +no_defs")
# have to fix projection issues
trans_temp <- st_transform(temp_df, projcrs)
temp_bris <- temp_df %>%
st_crop(st_bbox(bris_geo))
crs(bris_geo)
crs(trans_temp)
st_crs(bris_geo)
st_crs(trans_temp)
temp_bris <- trans_temp %>%
st_crop(st_bbox(bris_geo))
ggplot() +
geom_sf(data = temp_bris, aes(fill = temp, color=temp))
bris_geo$temp <- lengths(st_intersects(bris_geo, temp_bris))
ggplot() +
geom_sf(data = bris_geo, aes(fill = temp, color=temp))
View(temp_bris)
bris_geo$temp <- temp_bris
bris_geo$temp <- temp_bris[1:55]
bris_geo$temp <- st_intersects(bris_geo, temp_bris)
st_intersects(bris_geo, temp_bris)
View(green)
# Create centroid from polygons
pt <- st_centroid(bris_geo, of_largest_polygon = TRUE)
test <- st_join(pt,temp_bris)
test <- st_join(pt,temp_bris)
?st_join
plot(temp_df)
plot(trans_temp)
plot(trans_temp)
extract(trans_temp, bris_geo)
test <- rasterize(trans_temp,raster())
extract(test, bris_geo)
projection(test)
projection(bris_geo)
projection(trans_temp)
plot(test)
test <- rasterize(trans_temp,raster(),"temp")
plot(test)
test
r.raster <- raster(ncol=36, nrow=18)
r.raster[] <- 1:ncell(r.raster)
plot(r.raster)
r.raster
test <- rasterize(trans_temp,r.raster,field="temp")
plot(test)
temp_bris
extent(temp_bris)
test <- raster(crs = crs(temp_bris), vals = 0, resolution = c(0.5, 0.5), ext = extent(temp_bris) %>%
test <- raster(crs = crs(temp_bris), vals = 0, resolution = c(0.5, 0.5), ext = extent(temp_bris)) %>%
rasterize(temp_bris, .)
plot(test)
#up to here works. I have the temperature as an sf and on the same projection as bris_geo
# now its a matter of extracting the average value for each MSOA which I havent gotten to work yet
test <- raster(crs = crs(temp_bris), vals = 0, resolution = c(0.5, 0.5), ext = extent(temp_bris)) %>%
rasterize(temp_bris, ., field="temp")
plot(test)
test <- rasterFromXYZ(df)
test <- rasterFromXYZ(temp_df)
spg <- df
coordinates(spg) <- ~ x + y
coordinates(spg) <- ~ lon + lat
# coerce to SpatialPixelsDataFrame
gridded(spg) <- TRUE
# coerce to raster
rasterDF <- raster(spg)
rasterDF
plot(rasterDF)
#up to here works. I have the temperature as an sf and on the same projection as bris_geo
# now its a matter of extracting the average value for each MSOA which I havent gotten to work yet
test <- raster(crs = crs(trans_temp), vals = 0, resolution = c(0.5, 0.5), ext = extent(trans_temp)) %>%
rasterize(trans_temp, ., field="temp")
gc()
#up to here works. I have the temperature as an sf and on the same projection as bris_geo
# now its a matter of extracting the average value for each MSOA which I havent gotten to work yet
test <- raster(crs = crs(trans_temp), vals = 0, resolution = c(0.5, 0.5), ext = extent(trans_temp)) %>%
rasterize(trans_temp, ., field="temp")
extent(bris_geo)
tp <- crop(trans_temp,extent(bris_geo))
tp <- st_crop(trans_temp,extent(bris_geo))
plot(tp)
#up to here works. I have the temperature as an sf and on the same projection as bris_geo
# now its a matter of extracting the average value for each MSOA which I havent gotten to work yet
test <- raster(crs = crs(trans_temp), vals = 0, resolution = c(0.5, 0.5), ext = extent(trans_temp)) %>%
rasterize(trans_temp, ., field="temp")
#up to here works. I have the temperature as an sf and on the same projection as bris_geo
# now its a matter of extracting the average value for each MSOA which I havent gotten to work yet
test <- raster(crs = crs(trans_temp), vals = 0, resolution = c(0.5, 0.5), ext = extent(bris_geo)) %>%
rasterize(trans_temp, ., field="temp")
plot(test)
values(rasterDF) <- trans_temp$temp
plot(rasterDF)
values(rasterDF)
test <- rasterFromXYZ(trans_temp)
test <- rasterFromXYZ(temp_df)
spg <- df
coordinates(spg) <- ~ lon + lat
# coerce to SpatialPixelsDataFrame
gridded(spg) <- TRUE
# coerce to raster
rasterDF <- raster(spg)
crs(rasterDF) <- "+proj=longlat +datum=WGS84 +no_defs"
plot(rasterDF)
values(rasterDF) <- df$temp
rasterDF
View(temp_df)
View(df)
#test <- rasterFromXYZ(temp_df)
spg <- df
coordinates(spg) <- ~ lon + lat
proj4string(spg)=CRS("+proj=longlat +datum=WGS84 +no_defs") # set it to lat-long
# coerce to SpatialPixelsDataFrame
gridded(spg) <- TRUE
# coerce to raster
rasterDF <- raster(spg)
projection(rasterDF) <- "+proj=longlat +datum=WGS84 +no_defs"
plot(rasterDF)
#test <- rasterFromXYZ(temp_df)
spg <- df
coordinates(spg) <- ~ lon + lat
proj4string(spg)=CRS("+proj=longlat +datum=WGS84 +no_defs") # set it to lat-long
# coerce to SpatialPixelsDataFrame
gridded(spg) <- TRUE
# coerce to raster
rasterDF <- raster(spg)
projection(rasterDF) <- "+proj=longlat +datum=WGS84 +no_defs"
plot(rasterDF)
test <- rasterFromXYZ(temp_df)
test <- rasterFromXYZ(df)
######################
# Code for hotspot analysis of SMART patrol data
# by Jesse F. Abrams
######################
# Load libraries
library(spdep)
library(rgdal)
library(lattice)
library(raster)
library(rgeos)
library(hexbin)
library(colorspace)
library(viridis)
library(raster)
library(rgdal)
library(ggthemes) # theme_map()
library(ggpubr)
library(grid)
library(gridExtra)
library(lattice)
library(ggplot2)
# Set working directory
setwd("~/Documents/GitHub/smartR/objective2")
# Load data
threat <- raster("~/Dropbox (ScreenForBio)/Jesse's stuff/smartpatrol/objective2/Data/AllTraps_weighted_mean_2014_19.tif")
#threat <- flip(threat, 1)
new_extent <- extent(threat)
new_extent@xmin <- 107.4
new_extent@xmax <- 107.8
new_extent@ymin <- 15.9
new_extent@ymax <- 16.2
threat <- crop(threat,new_extent)
#cost <- raster("/Users/jesse/Desktop/wwf_optim/CC_slope_roads_river_lc_elevation.tif")
cost <- raster("/Users/jesse/Desktop/wwf_optim/roads_LCP_mean_200m_masked.tif")
cost <- resample(cost,threat)
cost <- crop(cost,new_extent)
cost <- mask(cost,threat)
neighborhoods <- readOGR(dsn="~/Dropbox (ScreenForBio)/Jesse's stuff/smartpatrol/objective2/Data/GIS_data", layer='HQNSLPAsnew', stringsAsFactors = F)
neighborhoods <- spTransform(neighborhoods, proj4string(threat))
plot(neighborhoods, col=terrain.colors(nrow(neighborhoods)))
stations <- readOGR(dsn="/Users/jesse/Desktop/wwf_optim", layer='Ranger Station', stringsAsFactors = F)
stations <- spTransform(stations, proj4string(threat))
plot(stations, add=TRUE)
roads <- readOGR(dsn="/Users/jesse/Desktop/wwf_optim", layer='roads', stringsAsFactors = F)
roads <- spTransform(roads, proj4string(threat))
plot(roads,add=TRUE)
stations <- crop(stations, neighborhoods)
roads <- crop(roads, neighborhoods)
roads = as(roads, "SpatialPointsDataFrame")
getisgrid <- rasterToPolygons(threat)
# Create the list of neighbors
neighbors <- poly2nb(getisgrid)
weighted_neighbors <- nb2listw(neighbors, zero.policy=T)
vals <- values(threat)
vals <- vals[!is.na(vals)]
# Perform the local G analysis (Getis-Ord GI*)
getisgrid$HOTSPOT = as.vector(localG(vals, weighted_neighbors))
#hotspot <- getisgrid
#hotspot@data$Detections_cumul_AllTraps <- NULL
hotspots <- rasterize(getisgrid,threat,"HOTSPOT")
range01 <- function(x){(x-min(x,na.rm=TRUE))/(max(x,na.rm=TRUE)-min(x,na.rm=TRUE))}
values(hotspots) <- range01(values(hotspots))
stations <- as.data.frame(stations@coords)
colnames(stations) <- c("X","Y","Z")
stations$Z <- NULL
#stations2 <- stations[c(6,5,7,8,4),]
roads <- as.data.frame(roads@coords)
colnames(roads) <- c("X","Y")
#stations$Z <- NULL
rangers <- threat
values(rangers) <- 0
rangers <- mask(rangers,threat)
station_cells <- cellFromXY(rangers,stations)
start <- rangers
street <- threat
values(street) <- 0
street <- mask(street,threat)
road_cells <- cellFromXY(street,roads)
start_cells <- append(road_cells,station_cells)
start[start_cells] <- 1
start[-start_cells] <- NA
# So the general idea here follows the logic from the paper I shared with you.
# We first select a starting point
# Then we select a random neighbor cell to go to from t=1 until t = whatever limit we set
# we select the random cell according to which has the highest transition probability
# calculate the patrol reward
# then we do this 1000 times (or however many) according to the algorithm above
# keep the top 10% of these routes
# use them to update the transition matrix
# then we repeat that until we reach convergence
library(reshape2)
library(raster)
library(foreach)
library(doParallel)
##### FUNCTIONS
calculate_reward <- function(reward_input, cell){
reward <- reward_input[cell]
return(reward)
}
calculate_cost <- function(costlayer,prev,cur){
tmp_cost <- abs(costlayer[prev]-costlayer[cur])
return(tmp_cost)
}
calculate_transition_cost <- function(cur,pot,tran_mat){
if(length(pot)==1) {
tran_mat[pot] <- abs(tran_mat[cur]-tran_mat[pot])
}
else {
for(j in 1:length(pot)){
tran_mat[pot[j]] <- abs(tran_mat[cur]-tran_mat[pot[j]])
}
}
return(tran_mat)
}
select_next_cell <- function(cost_layer,cell, transition_mat, covered,repnum){
potential_cells <- adjacent(cost_layer, cell, directions=8, pairs=FALSE, target=NULL, sorted=FALSE,
include=FALSE, id=FALSE)
potential_cells <- potential_cells[!potential_cells %in% covered]
potential_cells <- potential_cells[!is.na(transition_mat[potential_cells])]
if(length(potential_cells)==0) {
potential_cells <- adjacent(cost_layer, cell, directions=8, pairs=FALSE, target=NULL, sorted=FALSE,
include=FALSE, id=FALSE)
}
if(max(transition_mat[potential_cells],na.rm=TRUE)==0) {
potential_cells <- sample(x = adjacent(cost_layer, cell, directions=8, pairs=FALSE, target=NULL, sorted=FALSE,
include=FALSE, id=FALSE),
size=1)
}
potential_cells <- potential_cells[!is.na(transition_mat[potential_cells])]
if(repnum==1) {
transition_mat <- calculate_transition_cost(cell,potential_cells,transition_mat)
}
if(length(potential_cells)==1) {
next_cell <- potential_cells
} else {
next_cell <- sample(x=potential_cells,
size=1,
prob=transition_mat[potential_cells])
}
return(next_cell)
}
generate_route <- function(start_cell,trans_mat,cost_layer,reward_layer,t,repnum){
library(reshape2)
library(raster)
total_cost <- 0
total_reward <- 0
current_cell <- start_cell
cells_covered <- start_cell
while (total_cost < t){
previous_cell <- current_cell
current_cell <- select_next_cell(cost_layer,previous_cell,trans_mat,cells_covered,repnum)
total_reward <- total_reward + calculate_reward(reward_input=reward_layer,
cell=current_cell)
cost <- calculate_cost(cost_layer,previous_cell,current_cell)
total_cost <- total_cost + cost #cost_layer[current_cell]
cells_covered <- cbind(cells_covered,current_cell)
}
tmp_return <- list(cells_covered,total_reward)
return(tmp_return)
#return(total_reward)
}
ce <- function(numb,mat,cost,reward,start,total_time,repnum) {
#setup parallel backend to use many processors
cores=detectCores()
cl <- makeCluster(cores[1]-2) #not to overload computer
registerDoParallel(cl)
#clusterCall(cl, function(x) .libPaths(x), .libPaths())
rew <- rep(0,numb)
route <- vector(mode = "list", length = numb)
tmp_test <- foreach(o = 1:numb, .export=c("calculate_transition_cost","calculate_cost","calculate_reward", "generate_route","select_next_cell")) %dopar% {
#print(i)
#startcell <- rep(start,numb/5)
#startcell <- startcell[o]
startcell <- sample(start,1)
tryCatch({
tmp <- generate_route(start_cell=startcell,
trans_mat=mat,
cost_layer=cost,
reward_layer=reward,
t=total_time,
repnum)
}, error=function(e){})
}
stopCluster(cl)
gc()
for (k in 1:numb) {
rew[k]<-as.vector(tmp_test[[k]][2])
route[k]<-as.vector(tmp_test[[k]][1])
}
ten_percent <- 0.1 * numb
rew <- unlist(rew)
tmp2 <- sort(rew, decreasing = TRUE)
tmp_10 <- tmp2[ten_percent]
selected_routes <- route[which(rew>=tmp_10)]
return(selected_routes)
}
update_transition <- function(cost_matrix,tran_mat,select,numbr){
tmp1 <- unlist(select)
tmp3 <- as.data.frame(table(tmp1))
tmp3$tmp1 <- as.numeric(as.character(tmp3$tmp1))
#tran_mat@data@values[!is.na(tran_mat@data@values)] <- 0
tran_mat@data@values[tmp3$tmp1] <- as.vector(tmp3$Freq)/(numbr*0.1)
tran_mat@data@values <- ifelse(tran_mat@data@values>1, 1, tran_mat@data@values)
return(tran_mat)
}
range01 <- function(x){(x-min(x,na.rm=TRUE))/(max(x,na.rm=TRUE)-min(x,na.rm=TRUE))}
########## TESTING
reward_layer <- hotspots
cost_layer <- cost
transition_mat <- cost_layer
values(transition_mat) <- 1-range01(values(transition_mat))
numb<-1000
reps<-100
start<-start_cells
#start<-c(24155,24155)
for (i in 1:reps) {
#transition_mat <- (0.5*(1-cost_layer))+(0.5*transition_mat)
print(i)
test <- ce(numb,transition_mat,cost_layer,reward_layer,start=start,total_time=1000,repnum=i)
transition_mat <- update_transition(cost_layer,transition_mat,test,numb)
plot(transition_mat)
}
plot(cost_layer)
plot(cost)
plot(cost_layer)
7*24
